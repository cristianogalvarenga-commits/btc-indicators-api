from flask import Flask, jsonify
from flask_cors import CORS
import json
import os
from datetime import datetime
import requests
import threading
import time
import logging

# Importar o scraper atualizado
from coinmarketcap_scraper_v2 import CoinMarketCapScraper

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

class BTCIndicatorsAPI:
    def __init__(self):
        self.data_file = os.path.join(os.getcwd(), 'indicators_data.json')
        self.last_update = None
        self.indicators_data = {}
        self.scraper = CoinMarketCapScraper()
        self.load_data()
        
    def load_data(self):
        """Carrega dados do arquivo JSON ou inicializa com scraping"""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.indicators_data = data.get('indicators', {})
                    self.last_update = data.get('last_update')
                logger.info("Dados carregados do arquivo JSON.")
            else:
                logger.info("Arquivo JSON n√£o encontrado. Iniciando scraping inicial...")
                self.indicators_data = self.scraper.scrape_indicators()
                if self.indicators_data:
                    self.last_update = datetime.now().isoformat()
                    self.save_data()
                else:
                    logger.error("Falha ao coletar dados iniciais via scraping. Usando dados de fallback.")
                    self.indicators_data = self.scraper.get_fallback_data()
                    self.last_update = datetime.now().isoformat()
                    self.save_data()
        except Exception as e:
            logger.error(f"Erro ao carregar/inicializar dados: {e}. Usando dados de fallback.")
            self.indicators_data = self.scraper.get_fallback_data()
            self.last_update = datetime.now().isoformat()
            self.save_data()
    
    def calculate_proximity(self, current, reference, compare_type):
        """Calcula a proximidade ao topo"""
        if current is None or reference is None or reference == 0:
            return None
        
        try:
            if compare_type == ">=":
                if current >= reference:
                    return 100.0
                else:
                    return (current / reference) * 100
            elif compare_type == "<=": # L√≥gica inversa para domin√¢ncia do BTC
                if current <= reference:
                    return 100.0
                else:
                    # Quanto mais pr√≥ximo de 'reference' (por baixo), mais perto de 100%
                    max_dominance = 70.0 # Valor de domin√¢ncia considerado alto
                    if current >= max_dominance: # Se estiver muito alto, longe do topo
                        return 0.0
                    elif current <= reference: # Se j√° atingiu ou passou o ponto de refer√™ncia
                        return 100.0
                    else:
                        # Calcula a porcentagem de proximidade de forma inversa
                        return ((max_dominance - current) / (max_dominance - reference)) * 100
            else:
                return None
        except (ZeroDivisionError, TypeError):
            return None
    
    def analyze_indicators(self):
        """An√°lise completa de todos os indicadores"""
        logger.info(f"üöÄ [{datetime.now()}] Iniciando an√°lise dos indicadores BTC...")
        
        # For√ßar atualiza√ß√£o dos dados via scraping
        scraped_data = self.scraper.scrape_indicators()
        if scraped_data:
            self.indicators_data = scraped_data
            self.last_update = datetime.now().isoformat()
            self.save_data()
            logger.info("Dados atualizados via scraping.")
        else:
            logger.warning("Falha ao coletar dados via scraping. Usando dados existentes/fallback.")
            self.load_data()

        # Calcular estat√≠sticas
        in_cycle_count = 0
        total_proximity = 0
        valid_count = 0
        results = []
        
        for name, data in self.indicators_data.items():
            current = data.get('current')
            reference = data.get('reference')
            compare_type = data.get('compare', '>=')
            source = data.get('source', 'unknown')
            description = data.get('description', '')
            
            proximity = self.calculate_proximity(current, reference, compare_type)
            in_cycle_zone = False
            
            if proximity is not None:
                if proximity >= 100:
                    in_cycle_zone = True
                    in_cycle_count += 1
                
                total_proximity += proximity
                valid_count += 1
            
            results.append({
                'name': name,
                'current': current,
                'reference': reference,
                'proximity': proximity,
                'inCycleZone': in_cycle_zone,
                'compare': compare_type,
                'source': source,
                'description': description
            })
        
        # Calcular m√©dia
        average_proximity = total_proximity / valid_count if valid_count > 0 else 0
        
        # Status geral
        if average_proximity >= 85:
            overall_status = "üî¥ ALTO RISCO - Poss√≠vel fim de ciclo pr√≥ximo"
        elif average_proximity >= 70:
            overall_status = "üü° M√âDIO RISCO - Monitorar de perto"
        elif average_proximity >= 50:
            overall_status = "üü† ATEN√á√ÉO - Ciclo avan√ßando"
        else:
            overall_status = "üü¢ BAIXO RISCO - In√≠cio/meio do ciclo"
        
        summary = {
            'inCycleZone': in_cycle_count,
            'total': len(self.indicators_data),
            'validCount': valid_count,
            'averageProximity': average_proximity,
            'lastUpdate': datetime.now().isoformat(),
            'overallStatus': overall_status
        }
        
        self.last_update = datetime.now().isoformat()
        self.save_data()
        
        logger.info(f"‚úÖ An√°lise conclu√≠da: {in_cycle_count}/{valid_count} na zona, m√©dia {average_proximity:.1f}%")
        
        return {
            'indicators': results,
            'summary': summary
        }
    
    def save_data(self):
        """Salva dados no arquivo JSON"""
        try:
            data = {
                'indicators': self.indicators_data,
                'last_update': self.last_update or datetime.now().isoformat()
            }
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erro ao salvar dados: {e}")

# Inst√¢ncia global da API
api_instance = BTCIndicatorsAPI()

@app.route('/')
def home():
    return jsonify({
        "message": "üöÄ BTC Indicators API est√° funcionando!",
        "status": "online",
        "version": "1.0.0",
        "endpoints": [
            "/api/indicators - Todos os indicadores analisados",
            "/api/summary - Resumo da an√°lise",
            "/api/update - For√ßa atualiza√ß√£o",
            "/health - Status da API"
        ],
        "lastUpdate": api_instance.last_update
    })

@app.route('/api/indicators')
def get_indicators():
    """Retorna todos os indicadores analisados"""
    try:
        result = api_instance.analyze_indicators()
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/summary')
def get_summary():
    """Retorna apenas o resumo da an√°lise"""
    try:
        result = api_instance.analyze_indicators()
        return jsonify(result['summary'])
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/update')
def force_update():
    """For√ßa atualiza√ß√£o dos dados"""
    try:
        result = api_instance.analyze_indicators()
        return jsonify({
            "message": "‚úÖ Dados atualizados com sucesso!",
            "lastUpdate": result['summary']['lastUpdate'],
            "summary": result['summary']
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/health')
def health_check():
    """Health check para monitoramento"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "lastUpdate": api_instance.last_update,
        "uptime": "API est√° rodando normalmente"
    })

def auto_update():
    """Atualiza√ß√£o autom√°tica a cada 30 minutos"""
    while True:
        try:
            logger.info(f"üîÑ [{datetime.now()}] Executando atualiza√ß√£o autom√°tica...")
            api_instance.analyze_indicators()
            logger.info("‚úÖ Atualiza√ß√£o autom√°tica conclu√≠da!")
        except Exception as e:
            logger.error(f"‚ùå Erro na atualiza√ß√£o autom√°tica: {e}")
        
        # Aguarda 30 minutos (1800 segundos)
        time.sleep(1800)

if __name__ == '__main__':
    logger.info("üöÄ Iniciando BTC Indicators API...")
    logger.info("üìä Carregando dados iniciais...")
    
    # Fazer uma an√°lise inicial
    api_instance.analyze_indicators()
    
    # Iniciar thread de atualiza√ß√£o autom√°tica
    logger.info("‚è∞ Iniciando atualiza√ß√£o autom√°tica (a cada 30 minutos)...")
    update_thread = threading.Thread(target=auto_update, daemon=True)
    update_thread.start()
